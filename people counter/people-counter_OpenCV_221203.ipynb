{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02ef38e",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "* [Simple Object Tracking with OpenCV](https://pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/)\n",
    "* [SSD 수행하기 - OpenCV DNN 모듈](https://junha1125.github.io/blog/artificial-intelligence/2020-08-16-SSD2OpenCV/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e6138",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473dbbde",
   "metadata": {},
   "source": [
    "* Phase 1. Detecting (with the Centroid Tracking Algorithm)\n",
    "    - During the detection phase we are running our computationally more expensive object detector to (1) detect if new objects have entered our view, and (2) see if we can find objects that were “lost” during the tracking phase. For each detected object we create or update an object tracker with the new bounding box coordinates. Since our object detector is more computationally expensive we only run this phase once every N frames.\n",
    "\n",
    "\n",
    "* Phase 2. Tracking (with a MobileNet Single Shot Detector (SSD))\n",
    "    - When we are not in the “detecting” phase we are in the “tracking” phase. For each of our detected objects, we create an object tracker to track the object as it moves around the frame. Our object tracker should be faster and more efficient than the object detector. We’ll continue tracking until we’ve reached the N-th frame and then re-run our object detector. The entire process then repeats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9613e42",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step1.png\" width=\"300\"></td>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step2.png\" width=\"300\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step3.png\" width=\"300\"></td>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step4.png\" width=\"300\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dbe99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "import easydict\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592600b2",
   "metadata": {},
   "source": [
    "## Centroid Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ab230",
   "metadata": {},
   "source": [
    "### Motivating Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70dcc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90bb7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69646919, 0.28613933],\n",
       "       [0.22685145, 0.55131477]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old: there are two existing objects\n",
    "objectCentroids = np.random.uniform(size=(2,2))\n",
    "objectCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a0b60b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71946897, 0.42310646],\n",
       "       [0.9807642 , 0.68482974],\n",
       "       [0.4809319 , 0.39211752]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new: three objects are detected\n",
    "inputCentroids = np.random.uniform(size=(3,2))\n",
    "inputCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a4d35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13888478, 0.489671  , 0.24018263],\n",
       "       [0.50902789, 0.76564396, 0.29983435]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = dist.cdist(objectCentroids, inputCentroids)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29f3960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = D.min(axis=1).argsort()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c99823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = D.argmin(axis=1)[rows]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "147e7ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (1, 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(rows, cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de29d7",
   "metadata": {},
   "source": [
    "- D[0,0] implies that the first existing object will be matched with the first input centroid.\n",
    "- D[1,2] implies that the second existing object will be matched with the thrid input centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ea3f5",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c786f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=30):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict() # centroid\n",
    "        self.disappeared = OrderedDict() # number of consecutive frames marked as disappeared\n",
    "        \n",
    "        # store the number of maximum consecutive frames a given object is allowed\n",
    "        # to be marked as \"disappeared\" -> deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        \n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "        \n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        \n",
    "    def update(self, rects):\n",
    "        # if the list of input bounding box rectangles is empty\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                \n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "                    \n",
    "            return self.objects\n",
    "            \n",
    "        # initialize an array of input centroids for the current frame\n",
    "        # and loop over the bounding box rectangles\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "            \n",
    "        # when currently not tracking any objects -> register\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        # otherwise\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "            \n",
    "            # compute the distance between each pair of object centorids and input centroids\n",
    "            # and find the smallest value\n",
    "            print(\"objects:\", self.objects); print(\"\\n\")\n",
    "            print(\"exist:\" ,objectCentroids); print(\"\\n\") #############################################\n",
    "            print(\"new:\", inputCentroids); print(\"\\n\")\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "            print(\"D:\", D); print(\"\\n\\n\")\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            \n",
    "            # \n",
    "            usedRows, usedCols = set(), set()\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "                \n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[cols]\n",
    "                self.disappeared[objectID] = 0\n",
    "                \n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "            \n",
    "            #\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "            \n",
    "            # if the number of object centroids is equal or greater than the number of input centroids\n",
    "            # check if some of these objects have potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                for row in unusedRows:\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "                    \n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "            \n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "                    \n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7729b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CentroidTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb0b2e",
   "metadata": {},
   "source": [
    "* MobileNet SSD (https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c25aaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromTensorflow(\"./MobileNetSSD_v3_large_coco/frozen_inference_graph.pb\",\n",
    "                                    \"./MobileNetSSD_v3_large_coco/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"../video_input.mp4\")\n",
    "cap = cv2.VideoCapture(\"../video_input_02.mp4\")\n",
    "(H, W) = (None, None)\n",
    "confidence = 0.4\n",
    "\n",
    "# look over the frames from the video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or cv2.waitKey(1)>=0:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (416,416))\n",
    "    \n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.8, (W, H), (104.0, 177.0, 123.0), swapRB=True, crop=False) # mean-R, mean-G, mean-B\n",
    "#     blob = cv2.dnn.blobFromImage(frame, 0.9, (W, H), (0, 0, 0), swapRB=True, crop=False) # mean-R, mean-G, mean-B\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    rects = []\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # over the confidence & person only\n",
    "        if detections[0, 0, i, 2] > confidence and detections[0, 0, i, 1] == 1:\n",
    "#         if detections[0, 0, i, 2] > confidence:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "            rects.append(box.astype(\"int\"))\n",
    "            # draw a bounding box surrounding the object\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), thickness=2)\n",
    "    \n",
    "#     objects = ct.update(rects)\n",
    "    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df1eff",
   "metadata": {},
   "source": [
    "* YOLO (https://github.com/arunponnusamy/object-detection-opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92fae7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(\"./yolo_v3/yolov3.weights\",\"./yolo_v3/yolov3.cfg.txt\")\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    try:\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except:\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7656f69c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"../video_input.mp4\")\n",
    "cap = cv2.VideoCapture(\"../video_input_02.mp4\")\n",
    "(H, W) = (None, None)\n",
    "confidence = 0.3\n",
    "\n",
    "# look over the frames from the video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or cv2.waitKey(1)>=0:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (416,416))\n",
    "    \n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "    \n",
    "#     blob = cv2.dnn.blobFromImage(frame, 0.8, (W, H), (104.0, 177.0, 123.0), swapRB=True, crop=False) # mean-R, mean-G, mean-B\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.04, (W, H), (0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward(get_output_layers(net))\n",
    "    rects = []\n",
    "    confidences = []\n",
    "    \n",
    "    for out in detections:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            if scores[class_id] > confidence:\n",
    "                center_x = int(detection[0] * W)\n",
    "                center_y = int(detection[1] * H)\n",
    "                w = int(detection[2] * W)\n",
    "                h = int(detection[3] * H)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "#                 box = np.array([x,y,w,h])\n",
    "#                 rects.append(box.astype(\"int\"))\n",
    "                rects.append([x,y,w,h])\n",
    "                confidences.append(float(scores[class_id]))\n",
    "#                 cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), thickness=2)\n",
    "    \n",
    "    for i in range(len(rects)):\n",
    "        if i in cv2.dnn.NMSBoxes(rects, confidences, 0.4, 0.4):\n",
    "            x, y, w, h = rects[i]\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), thickness=2)\n",
    "    \n",
    "    \n",
    "#     objects = ct.update(rects)\n",
    "    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08aa64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c059f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e03ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([316, 130]), array([315, 146])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old = [np.array([316,130]), np.array([315,146])]\n",
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "595a5edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316, 130],\n",
       "       [315, 146]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = np.array([[316,130], [315,146]])\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9af40c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 16.03121954],\n",
       "       [16.03121954,  0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.cdist(np.array(old), new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d48606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfa842c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[316, 130],\n",
       "        [315, 146]],\n",
       "\n",
       "       [[316, 130],\n",
       "        [315, 146]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old = [np.array([[316,130], [315,146]]), np.array([[316,130], [315,146]])]\n",
    "np.array(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed963be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[314, 129]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = np.array([[314,129]])\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.cdist(np.array(old), new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5f0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701ea48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc986db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21aa2e3e",
   "metadata": {},
   "source": [
    "## Creating a trackable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be0f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackableObject:\n",
    "    def __init__(self, objectID, centroid):\n",
    "        # store the object ID and initialize a list of centroid location history\n",
    "        self.objectID = objectID\n",
    "        self.centroids = [centroid]\n",
    "        \n",
    "        # check if the object has already been counted or not\n",
    "        self.counted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a43ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255c04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
