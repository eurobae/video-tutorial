{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5e6138",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473dbbde",
   "metadata": {},
   "source": [
    "* Phase 1. Detecting (with the Centroid Tracking Algorithm)\n",
    "    - During the detection phase we are running our computationally more expensive object detector to (1) detect if new objects have entered our view, and (2) see if we can find objects that were “lost” during the tracking phase. For each detected object we create or update an object tracker with the new bounding box coordinates. Since our object detector is more computationally expensive we only run this phase once every N frames.\n",
    "\n",
    "\n",
    "* Phase 2. Tracking (with a MobileNet Single Shot Detector (SSD))\n",
    "    - When we are not in the “detecting” phase we are in the “tracking” phase. For each of our detected objects, we create an object tracker to track the object as it moves around the frame. Our object tracker should be faster and more efficient than the object detector. We’ll continue tracking until we’ve reached the N-th frame and then re-run our object detector. The entire process then repeats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9613e42",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step1.png\" width=\"300\"></td>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step2.png\" width=\"300\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step3.png\" width=\"300\"></td>\n",
    "        <td><img src=\"https://pyimagesearch.com/wp-content/uploads/2018/07/simple_object_tracking_step4.png\" width=\"300\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dbe99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f48651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "592600b2",
   "metadata": {},
   "source": [
    "## Centroid Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e442365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de29d7",
   "metadata": {},
   "source": [
    "* Simple example\n",
    "    - D[0,0] implies that the first existing object will be matched with the first input centroid.\n",
    "    - D[1,2] implies that the second existing object will be matched with the thrid input centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70dcc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a90bb7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69646919, 0.28613933],\n",
       "       [0.22685145, 0.55131477]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old: there are two existing objects\n",
    "objectCentroids = np.random.uniform(size=(2,2))\n",
    "objectCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a0b60b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71946897, 0.42310646],\n",
       "       [0.9807642 , 0.68482974],\n",
       "       [0.4809319 , 0.39211752]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new: three objects are detected\n",
    "inputCentroids = np.random.uniform(size=(3,2))\n",
    "inputCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50a4d35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13888478, 0.489671  , 0.24018263],\n",
       "       [0.50902789, 0.76564396, 0.29983435]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = dist.cdist(objectCentroids, inputCentroids)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d29f3960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = D.min(axis=1).argsort()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92c99823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = D.argmin(axis=1)[rows]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147e7ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (1, 2)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(rows, cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ea3f5",
   "metadata": {},
   "source": [
    "* Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9c786f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=30):\n",
    "        # initiliaze the next unique object ID along with two ordered dictionaries\n",
    "        # used to keep track of mapping a given object ID to its centroid and\n",
    "        # number of consecutive frames it has been marked as \"disappeared\"\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        \n",
    "        # store the number of maximum consecutive frames a given object is allowed\n",
    "        # to be marked as \"disappeared\" until we need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        \n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        slef.nextObjectID += 1\n",
    "        \n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        \n",
    "    def update(self, rects):\n",
    "        # check if the list of input bounding box rectangles is empty\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                \n",
    "                # if reached a maximum number of conseuctive frames where a given object\n",
    "                # has been marked as missing, then deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "                    \n",
    "            return self.objects\n",
    "            \n",
    "        # initialize an array of input centroids for the current frame\n",
    "        # and loop over the bounding box rectangles\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "            \n",
    "        # when currently not tracking any objects -> register\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        # otherwise, when tracking objects\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "            \n",
    "            # compute the distance between each pair of object centorids and input centroids\n",
    "            # and find the smallest value\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            \n",
    "            # \n",
    "            usedRows, usedCols = set(), set()\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "                \n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[cols]\n",
    "                self.disappeared[objectID] = 0\n",
    "                \n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "            \n",
    "            #\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "            \n",
    "            # if the number of object centroids is equal or greater than the number of input centroids\n",
    "            # check if some of these objects have potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                for row in unusedRows:\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "                    \n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "            \n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "                    \n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729b7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f00a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CentroidTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8cf8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(H, W) = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94044f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d869f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53e65be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../video_input.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look over the frames from the video\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()    \n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    \n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (W, H),\n",
    "                                 (104.0, 177.0, 123.0))    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5060a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b21da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc986db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21aa2e3e",
   "metadata": {},
   "source": [
    "## Creating a trackable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be0f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackableObject:\n",
    "    def __init__(self, objectID, centroid):\n",
    "        # store the object ID and initialize a list of centroid location history\n",
    "        self.objectID = objectID\n",
    "        self.centroids = [centroid]\n",
    "        \n",
    "        # check if the object has already been counted or not\n",
    "        self.counted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a43ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255c04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
